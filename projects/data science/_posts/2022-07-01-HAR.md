---
layout: post
title: "Smartphone Human Activity Recognition"
sitemap: false
hide_last_modified: true
permalink: /projects/data science/HAR/
related_posts:
    -
sitemap: false
image: \assets\project/har.png
---

# Smartphone Human Activity Recognition
As a member of the projects committee of the Data Science Student Society at UCSD, I took part in a project that involved analyzing a dataset from UCI that included sensory data from the built in accelerometer and gyroscope in a persons' smartphone as they went through with various physical activties such as sitting down, standing up, and laying down ([Dataset](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones)). We would then go on to train and test multiple machine learning algorithms to determine which predicted the human movement best given the physical data.

- To see the results, code, and other details, check out the [Github](https://github.com/amhurtad/DS3-Human-Phone-Activity)

